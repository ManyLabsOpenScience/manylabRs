#' Huang.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#huang}
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return A \code{list} object containing fields \strong{High}, \strong{Low} and \strong{N}
#' @export
#'
#' @details \strong{Analysis plan:} The coordinates of the click on the map will be recorded (X, Y) from the top-left of the image. The mean difference between the high and low-SES conditions for north/south location of click (Y) will be compared with an independent samples t-test. All participants who indicate an area within the boundaries of the map will be included in the analysis.
#'
#' @section Variables:
#'
#' huan1.1_Y1: Y position of the mouse (High SES condition).
#' huan2.1_Y1: Y position of the mouse (Low SES).
#' huan1.1_R0 and huan2.1_R0 indicate for each condition whether a click was inside the map (1) or outside (0).
#'
#' For each condition a participant must have clicked inside the map (=1) to be included in the analysis.
#'
varfun.Huang.1 <- function(vars){
    return(list(High = -1*(vars$High[[1]]-238),
                Low  = -1*(vars$Low[[1]]-238),
                N    = c(nrow(vars$High),nrow(vars$Low)))
           )
}

#' varfun.Kay.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#kay}
#'
#' @param vars      A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} Following Kay et al. (2014), we will create an index of willingness to engage in goal pursuit for each participant by
#' (1) regressing the mean of the two goal pursuit items on the centered mean of the goal subjective value item,
#' (2) calculating the unstandardized residual for each participant, and
#' (3) add to those the mean value for the self-regulation items measuring willingness to engage in goal pursuit.
#'
#' Then, the two conditions will be compared using an independent samples t-test.
#'
#' @examples
varfun.Kay.1 <- function(vars){
#   require(dplyr)

    var.Order <- rowMeans(dplyr::select(vars$Order, one_of(c('kay1.5','kay1.6'))))
    # [(1) Centered Subjective value = (GP1 + GP2)]$(2)residuals + (3) mean Willingness to engage in goal pursuit
    var.windex.Order <-lm(scale(vars$Order$kay1.4,scale=F)~var.Order)$residuals + var.Order

    var.DisOrder <- rowMeans(dplyr::select(vars$DisOrder,one_of(c('kay2.5','kay2.6'))))
    # [(1) Centered Subjective value = (GP1 + GP2)]$(2)residuals + (3) mean Willingness to engage in goal pursuit
    var.windex.DisOrder <-lm(scale(vars$DisOrder$kay2.4,scale=F)~var.DisOrder)$residuals + var.DisOrder

    return(list(Order=var.windex.Order,
                DisOrder=var.windex.DisOrder,
                N = c(length(var.windex.Order),length(var.windex.DisOrder)))
           )
}

#' varfun.Alter.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#alter}
#'
#' @param vars       A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} Similar to Alter et al. (2007), we will conduct an independent samples ttest to determine whether accuracy in solving moderately difficult syllogisms differ by font condition (fluent versus disfluent).
#'
#' The original study focused on the moderately difficult questions, on the basis that participants' performance could vary enough to detect changes in processing depth.
#' Our primary analysis strategy will be sensitive to potential differences across samples in ability on syllogisms.
#' We will first determine which syllogisms were moderately difficult to participants by excluding any of the six items, within each sample, that were answered correctly by fewer than 25% of participants or more than 75\% of participants across conditions.
#' The remaining syllogisms will be the basis of computing mean syllogism performance for each participant. F
#' or a direct comparison with the original effect size, only English in-lab samples will be used for two reasons:
#' (1) we cannot adequately control for online participants "zooming in" on the page or otherwise making the font more readable, and
#' (2) a different font may be used in some translated versions because the original font (Myriad Web) may not support all languages.
#'
#' All samples will be included in the investigation of cross-site variability in effect size.
#'
#' @section Variables:
#'
#'   Syllogisms to include for each sample
#'   INCLUSION PERCENTAGE BASED ON
#'    FLUENT / DISFLUENT SEPERATELY: 1 5 6
#'    BOTH: 1 5 6
#'
#' @examples
varfun.Alter.1 <- function(vars){
    var.correct <- list(s1=c(7),
                        s2=c(8),
                        s3=c(5,6,7,8),
                        s4=c(8),
                        s5=c(3),
                        s6=c(8))

    lowP <- .25
    hiP  <- .75

    # Get correct answers
    ok.Fluent   <- sapply(seq_along(vars$Fluent), function(c) unlist(vars$Fluent[,c])%in%var.correct[[c]])
    ok.DisFluent<- sapply(seq_along(vars$DisFluent), function(c) unlist(vars$DisFluent[,c])%in%var.correct[[c]])

    # Find columns
    # Syllogisms to include for each sample
    # INCLUSION PERCENTAGE BASED ON
    # FLUENT / DISFLUENT SEPERATELY: 1 5 6
    # BOTH: 1 5 6
#     id.Fluent.cols    <- which((colSums(ok.Fluent)/nrow(ok.Fluent)>lowP)&(colSums(ok.Fluent)/nrow(ok.Fluent)<hiP))
#     id.DisFluent.cols <- which((colSums(ok.DisFluent)/nrow(ok.DisFluent)>lowP)&(colSums(ok.DisFluent)/nrow(ok.DisFluent)<hiP))

    id.Fluent.cols    <- c(1, 5, 6)
    id.DisFluent.cols <- c(1, 5, 6)

    return(list(Fluent    = rowSums(rbind(ok.Fluent[ ,id.Fluent.cols])),
                DisFluent = rowSums(rbind(ok.DisFluent[ ,id.DisFluent.cols])),
                N = c(nrow(ok.Fluent),nrow(ok.DisFluent)))
           )
}

#' varfun.Alter.2
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#alter}
#'
#' @param vars       A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} Similar to Alter et al. (2007), we will conduct an independent samples ttest to determine whether accuracy in solving moderately difficult syllogisms differ by font condition (fluent versus disfluent).
#'
#' The original study focused on the moderately difficult questions, on the basis that participants' performance could vary enough to detect changes in processing depth.
#' Our primary analysis strategy will be sensitive to potential differences across samples in ability on syllogisms.
#' We will first determine which syllogisms were moderately difficult to participants by excluding any of the six items, within each sample, that were answered correctly by fewer than 25% of participants or more than 75\% of participants across conditions.
#' The remaining syllogisms will be the basis of computing mean syllogism performance for each participant. F
#' or a direct comparison with the original effect size, only English in-lab samples will be used for two reasons:
#' (1) we cannot adequately control for online participants "zooming in" on the page or otherwise making the font more readable, and
#' (2) a different font may be used in some translated versions because the original font (Myriad Web) may not support all languages.
#'
#' All samples will be included in the investigation of cross-site variability in effect size.
#'
#' @section Variables:
#'
#'   Syllogisms to include for each sample
#'   INCLUSION PERCENTAGE BASED ON
#'    FLUENT / DISFLUENT SEPERATELY: 1 5 6
#'    BOTH: 1 5 6
#'
#' @examples
varfun.Alter.2 <- function(vars){
    var.correct <- list(s1=c(7),
                        s2=c(8),
                        s3=c(5,6,7,8),
                        s4=c(8),
                        s5=c(3),
                        s6=c(8))

    # Get correct answers
    ok.Fluent   <- sapply(seq_along(vars$Fluent), function(c) unlist(vars$Fluent[,c])%in%var.correct[[c]])
    ok.DisFluent<- sapply(seq_along(vars$DisFluent), function(c) unlist(vars$DisFluent[,c])%in%var.correct[[c]])

    # Syllogisms to include for each sample
    # First and last
    id.Fluent.cols      <- c(1,6)
    id.DisFluent.cols   <- c(1,6)

    return(list(Fluent    = rowSums(ok.Fluent[,id.Fluent.cols]),
                DisFluent = rowSums(ok.DisFluent[,id.DisFluent.cols]),
                N = c(nrow(ok.Fluent),nrow(ok.DisFluent)))
           )
}

#' varfun.Alter.3
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#alter}
#'
#' @param vars      A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} Similar to Alter et al. (2007), we will conduct an independent samples ttest to determine whether accuracy in solving moderately difficult syllogisms differ by font condition (fluent versus disfluent).
#'
#' The original study focused on the moderately difficult questions, on the basis that participants' performance could vary enough to detect changes in processing depth.
#' Our primary analysis strategy will be sensitive to potential differences across samples in ability on syllogisms.
#' We will first determine which syllogisms were moderately difficult to participants by excluding any of the six items, within each sample, that were answered correctly by fewer than 25% of participants or more than 75\% of participants across conditions.
#' The remaining syllogisms will be the basis of computing mean syllogism performance for each participant. F
#' or a direct comparison with the original effect size, only English in-lab samples will be used for two reasons:
#' (1) we cannot adequately control for online participants "zooming in" on the page or otherwise making the font more readable, and
#' (2) a different font may be used in some translated versions because the original font (Myriad Web) may not support all languages.
#'
#' All samples will be included in the investigation of cross-site variability in effect size.
#'
#'
#' @section Variables:
#'
#'   Syllogisms to include for each sample
#'   INCLUSION PERCENTAGE BASED ON
#'    FLUENT / DISFLUENT SEPERATELY: 1 5 6
#'    BOTH: 1 5 6
#'    @examples
varfun.Alter.3 <- function(vars){

        var.correct <- list(s1=c(7),
                        s2=c(8),
                        s3=c(5,6,7,8),
                        s4=c(8),
                        s5=c(3),
                        s6=c(8))

    # Get ids for Alter first
    id <- sapply(seq_along(vars$RawDataFilter[[1]]$.id), function(i) unlist(strsplit(x = vars$RawDataFilter[[1]]$StudyOrderN[i], split = "[|]"))[[1]] == "Alter")

    # Get correct answers for ids Alter first
    if(sum(id,na.rm=T)>0){
        ok.Fluent   <- rbind(sapply(seq_along(vars$Fluent), function(c) unlist(vars$Fluent[id, c])%in%var.correct[[c]]))
        ok.DisFluent<- rbind(sapply(seq_along(vars$DisFluent), function(c) unlist(vars$DisFluent[id, c])%in%var.correct[[c]]))
    } else {
        ok.Fluent    <- rep(FALSE,6)
        ok.DisFluent <- rep(FALSE,6)
    }

    # Use 1,5,6
    id.Fluent.cols    <- c(1,5,6)
    id.DisFluent.cols <- c(1,5,6)

    return(list(Fluent    = rowSums(rbind(ok.Fluent[ ,id.Fluent.cols])),
                DisFluent = rowSums(rbind(ok.DisFluent[ ,id.DisFluent.cols])),
                N = c(nrow(ok.Fluent),nrow(ok.DisFluent)))
    )
}


#' varfun.Alter.4
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#alter}
#'
#' @param vars      A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} Similar to Alter et al. (2007), we will conduct an independent samples ttest to determine whether accuracy in solving moderately difficult syllogisms differ by font condition (fluent versus disfluent).
#'
#' The original study focused on the moderately difficult questions, on the basis that participants' performance could vary enough to detect changes in processing depth.
#' Our primary analysis strategy will be sensitive to potential differences across samples in ability on syllogisms.
#' We will first determine which syllogisms were moderately difficult to participants by excluding any of the six items, within each sample, that were answered correctly by fewer than 25% of participants or more than 75\% of participants across conditions.
#' The remaining syllogisms will be the basis of computing mean syllogism performance for each participant. F
#' or a direct comparison with the original effect size, only English in-lab samples will be used for two reasons:
#' (1) we cannot adequately control for online participants "zooming in" on the page or otherwise making the font more readable, and
#' (2) a different font may be used in some translated versions because the original font (Myriad Web) may not support all languages.
#'
#' All samples will be included in the investigation of cross-site variability in effect size.
#'
#' @section Variables:
#'   Syllogisms to include for each sample
#'   INCLUSION PERCENTAGE BASED ON
#'    FLUENT / DISFLUENT SEPERATELY: 1 5 6
#'    BOTH: 1 5 6
#' @examples
varfun.Alter.4 <- function(vars){
    var.correct <- list(s1=c(7),
                        s2=c(8),
                        s3=c(5,6,7,8),
                        s4=c(8),
                        s5=c(3),
                        s6=c(8))

    # Get ids for Alter first
    id <- sapply(seq_along(vars$RawDataFilter[[1]]$.id), function(i) unlist(strsplit(x = vars$RawDataFilter[[1]]$StudyOrderN[i], split = "[|]"))[[1]] == "Alter")

    # Get correct answers for ids Alter first
    if(sum(id,na.rm=T)>0){
        ok.Fluent   <- rbind(sapply(seq_along(vars$Fluent), function(c) unlist(vars$Fluent[id, c])%in%var.correct[[c]]))
        ok.DisFluent<- rbind(sapply(seq_along(vars$DisFluent), function(c) unlist(vars$DisFluent[id, c])%in%var.correct[[c]]))
    } else {
        ok.Fluent    <- rep(FALSE,6)
        ok.DisFluent <- rep(FALSE,6)
    }

    # Syllogisms to include for each sample
    # First and last
    id.Fluent.cols      <- c(1,6)
    id.DisFluent.cols   <- c(1,6)

    return(list(Fluent    = rowSums(rbind(ok.Fluent[ ,id.Fluent.cols])),
                DisFluent = rowSums(rbind(ok.DisFluent[ ,id.DisFluent.cols])),
                N = c(nrow(ok.Fluent),nrow(ok.DisFluent)))
           )
}

#' varfun.Graham.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#graham}
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @description   The 9 items for ingroup, authority, and purity will be averaged to create a "binding" foundations moral relevance score.
#' The relationship between political ideology and the "binding" aggregates will be calculated using zero order correlations.
#'
#'  The primary target of replication is the relationship of political ideology with the "binding" foundations.
#'
#'  All participants who complete the corresponding measures will be included in analysis.
#'
#' @examples
varfun.Graham.1 <- function(vars){
    return(list(Politics = vars$Politics$politics,
                Binding  = rowMeans(vars$Binding,na.rm=T),
                N        = sum(complete.cases(rowMeans(vars$Binding,na.rm=T), vars$Politics$politics)))
           )
}

#' varfun.Graham.2
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#graham}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details   The 6 items for harm and fairness will be averaged to create a "individualizing" foundations moral relevance score.
#' The relationship between political ideology and "individualizing" aggregates will be calculated using zero order correlations.
#'
#'  The relationship of political ideology with the "individualizing" foundations is a secondary replication.
#'
#'  All participants who complete the corresponding measures will be included in analysis.
#'
#' @examples
varfun.Graham.2 <- function(vars){
    return(list(Politics   = vars$Politics$politics,
                Individual = rowMeans(vars$Individual, na.rm = TRUE),
                N          = sum(complete.cases(rowMeans(vars$Individual,na.rm=TRUE), vars$Politics$politics)))
           )
}

#' varfun.Rottenstreich.1
#'
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#rottenstreich}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details  \strong{Analysis plan:} A two-way contingency table will be built with certainty condition (lowprobability
#' vs. certain) and choice (monetary reward vs. meeting favorite movie star) as factors.
#' The critical replication hypothesis will be given by a Fisher Exact test and the effect size by an odds ratio.
#' All participants with valid data on the response will be included in the analysis.
#'
#' @examples
varfun.Rottenstreich.1 <- function(vars){
    return(list(Response  = factor(c(vars$Low[[1]],vars$Certain[[1]]),levels=c(1,2),labels=vars$labels$Response),
                Condition = factor(c(rep(1,nrow(vars$Low)),rep(2,nrow(vars$Certain))),levels=c(1,2),labels=vars$labels$Condition),
                N      = c(nrow(vars$Certain),nrow(vars$Low)))
           )
}

#' varfun.Bauer.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#bauer}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} We will compare the mean trust levels between conditions with an independent samples t-test.
#' All participants with data will be included in analysis
#' Known differences from original. The original experiment included four additional dependent Variables:
#' (1) responsibility for the crisis,
#' (2) obligation to cut water usage,
#' (3) howmuch they viewed others as partners, and (4) how much others should use less water.
#'
#' The central replication will be on the trust variable, while the other four dependent Variables: will be retained in the procedure but not analyzed for the focal replication.
#'
#' @examples
varfun.Bauer.1 <- function(vars){
    return(list(Consumer  = vars$Consumer[[2]],
                Individual= vars$Individual[[2]],
                N         = c(length(vars$Consumer[[2]]),length(vars$Individual[[2]])))
           )
}

#' varfun.Miyamoto.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#Miyamoto}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details  \strong{Analysis plan:} An ANCOVA will compare the mean estimates of the author's true attitude across the two conditions, covarying for perceived constraint.
#'
#' @section Variables:
#' miya1.5=true attitude (pro-death condition; higher values=higher support for death penalty);
#' miya1.7=perceived constraint (pro-death condition; higher values=higher freedom);
#'
#' miya2.5=true attitude (against death penalty condition; higher values=higher support for death penalty);
#' miya2.7=perceived constraint (against death condition; higher values= higher freedom).
#' @examples
varfun.Miyamoto.1 <- function(vars){
    return(list(Attitude  = c(vars$CapitalCon[[1]],vars$CapitalPro[[1]]),
                Condition = factor(c(rep(1,nrow(vars$CapitalCon)),rep(2,nrow(vars$CapitalPro))),levels=c(1,2),labels=vars$labels$Condition),
                Constraint= scale(c(vars$CapitalCon[[2]],vars$CapitalPro[[2]]), scale = FALSE),
                N = c(nrow(vars$CapitalCon),nrow(vars$CapitalPro)))
           )
}

#' varfun.Miyamoto.2
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#Miyamoto}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details  \strong{Analysis plan:} An ANCOVA will compare the mean estimates of the author's true attitude across the two conditions, covarying for perceived constraint.
#'
#' @section Variables:
#' miya1.5=true attitude (pro-death condition; higher values=higher support for death penalty);
#' miya1.7=perceived constraint (pro-death condition; higher values=higher freedom);
#'
#' miya2.5=true attitude (against death penalty condition; higher values=higher support for death penalty);
#' miya2.7=perceived constraint (against death condition; higher values= higher freedom).
#' @examples
varfun.Miyamoto.2 <- function(vars){
    return(list(Attitude  = c(vars$CapitalCon[[1]],vars$CapitalPro[[1]]),
                Condition = factor(c(rep(1,nrow(vars$CapitalCon)),rep(2,nrow(vars$CapitalPro))),levels=c(1,2),labels=vars$labels$Condition),
                Constraint= scale(c(vars$CapitalCon[[2]],vars$CapitalPro[[2]]), scale=FALSE),
                Moderator = scale(c(vars$CapitalCon[[3]],vars$CapitalPro[[3]]), scale=FALSE),
                N = c(nrow(vars$CapitalCon),nrow(vars$CapitalPro)))
    )
}




#' varfun.Inbar.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#inbar}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details  \strong{Analysis plan:} The five items of the contamination subscale of the Disgust Sensitivity Scale-Revised will be averaged to create a single index of disgust sensitivity.
#' For the primary analysis, we will compute a correlation between disgust sensitivity and assessments of the director's intentionality in both the gay kissing and kissing conditions,
#' and then compare the correlations with an r-to-z transformation.
#' The other two outcome measures will be examined as secondary analyses following the same analysis strategy.
#' All participants with relevant data will be included in analysis.
#'
#' @section Variables:
#' disg1.11,disg1.12,disg2.10,disg2.12,disg2.13;
#'
#' responses on the DS-R are scored as follows: True 1, False 0; Not disgusting 0, Slightly disgusting 0.5, Very disgusting 1
#'
#' @examples
varfun.Inbar.1 <- function(vars){
#   require(dplyr)

    vars$SameKiss$disg1.11 <- -vars$SameKiss$disg1.11
    vars$SameKiss$disg1.12 <- -vars$SameKiss$disg1.12
    vars$DiffKiss$disg1.11 <- -vars$DiffKiss$disg1.11
    vars$DiffKiss$disg1.12 <- -vars$DiffKiss$disg1.12

    vars$SameKiss <- dplyr::mutate(vars$SameKiss,
                                   DSRs = rowMeans(scaleR(dplyr::select(vars$SameKiss, starts_with("disg"))), na.rm = TRUE)
                                   )
    vars$DiffKiss <- dplyr::mutate(vars$DiffKiss,
                                   DSRd = rowMeans(scaleR(dplyr::select(vars$DiffKiss, starts_with("disg"))), na.rm = TRUE)
                                   )

    outcome <- c("Intent","Wrong","Encourage")[colnames(vars$SameKiss)[1]==c("inba1.3","inba1.4","inba1.5")]

    colnames(vars$SameKiss)[1] <- outcome
    colnames(vars$DiffKiss)[1] <- outcome

    return(list(r1=cbind(vars$SameKiss['DSRs'],vars$SameKiss[outcome]),
                r2=cbind(vars$DiffKiss['DSRd'],vars$DiffKiss[outcome]),
                N = c(nrow(vars$SameKiss),nrow(vars$DiffKiss)))
    )
}



#' varfun.Inbar.2
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#inbar}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @examples
varfun.Inbar.2 <- function(vars){
    return(list(SameKiss= vars$SameKiss[[1]],
                DiffKiss= vars$DiffKiss[[1]],
                N =  c(nrow(vars$SameKiss),nrow(vars$DiffKiss)))
    )
}


#' varfun.Critcher.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#critcher}
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details  \strong{Analysis plan:} The means for the P97 and P17 groups will be compared with an
#' independent samples t-test. Participants whose answers will not fall between 0 and 100 will be excluded from analysis.
#'
#' @section Variables:
#'  crit1.1= % sold P97 in the US;
#'  crit2.1= % sold P17 in the US
#'
#'  df.P97 <- dplyr::select(tbl_df(ML2.df),which(colnames(ML2.df)%in%ML2.in$study.vars$Condition[1]))
#'  df.P97 <- slice(df.P97, which((ML2.id[[1]][,1]==T)&(ML2.id[[2]][,1]==T)))
#'
#'   df.P17 <- dplyr::select(tbl_df(ML2.df),which(colnames(ML2.df)%in%ML2.in$study.vars$Condition[2]))
#'   df.P17 <- slice(df.P17, which((ML2.id[[1]][,2]==T)&(ML2.id[[2]][,2]==T)))
#'
#'   id.P97 <- ML2.df[ML2.id[[1]][,1]&ML2.id[[2]][,1],ML2.in$study.vars$Condition[1]]
#'   id.P17 <- ML2.df[ML2.id[[1]][,2]&ML2.id[[2]][,2],ML2.in$study.vars$Condition[2]]
#'
#' @examples
varfun.Critcher.1 <- function(vars){
    return(list(P97    = as.numeric(vars$P97$crit1.1),
                P17    = as.numeric(vars$P17$crit2.1),
                N      =  c(nrow(vars$P97),nrow(vars$P17)))
           )
}

#' van.Lange.1
#'
#' @description \url{http://fredhasselman.com/htmlHost/ManyLabs/ML2_PoPS_proposal.html#vanlange}
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return A \code{list} object containing fields \strong{SVO}, \strong{Siblings} and \strong{N}
#' @export
#' @details \strong{Analysis plan:} The current replication focuses only on the observed direct positive correlation between greater prosocial orientation and number of siblings.
#'
#'   Participants must respond to all 6 items of the SVO slider and have valid data for the two questions asking about older and younger siblings, to be included in the analysis. Total number of siblings will be obtained by adding the number of younger and older siblings.
#'
#'   SVO slider scores will be scored in according to the procedure recommended by Murphy et al. (2011). The resulting SVO slide score will be correlated with the total number of siblings for the critical test.

#' @section Variables:
#'    van.p.1.2_1 TO van.p.1.2_6 are the items of SVO measure.
#'
#'   murphy et al. (2011) scoring: SVO degress=arctan [(mean Alloc other - 50)/(mean Allocation self - 50)].
#'
#'   See SVO codes (this doc) for the list of paired amounts
#'   van.p2.1_1_TEXT= # of older siblings;
#'   van.p2.1_2_TEXT= # of younger siblings.
#'
#' @examples
varfun.vanLange.1 <- function(vars){

    SVO <-rbind(cbind(c( 85,85 ), c( 85,76 ), c( 85,68 ), c( 85,59 ), c( 85,50 ), c( 85,41 ), c( 85,33 ), c( 85,24 ), c( 85,15 )),
                cbind(c( 85,15 ), c( 87,19 ), c( 89,24 ), c( 91,28 ), c( 93,33 ), c( 94,37 ), c( 96,41 ), c( 98,46 ), c( 100,50 )),
                cbind(c( 50,100 ), c( 54,98 ), c( 59,96 ), c( 63,94 ), c( 68,93 ), c( 72,91 ), c( 76,89 ), c( 81,87 ), c( 85,85 )),
                cbind(c( 50,100 ), c( 54,89 ), c( 59,79 ), c( 63,68 ), c( 68,58 ), c( 72,47 ), c( 76,36 ), c( 81,26 ), c( 85,15 )),
                cbind(c( 100,50 ), c( 94,56 ), c( 88,63 ), c( 81,69 ), c( 75,75 ), c( 69,81 ), c( 63,88 ), c( 56,94 ), c( 50,100 )),
                cbind(c( 100,50 ), c( 98,54 ), c( 96,59 ), c( 94,63 ), c( 93,68 ), c( 91,72 ), c( 89,76 ), c( 87,81 ), c( 85,85 )))

    SVO.self  <- SVO[seq(1,11,by=2), ]
    SVO.other <- SVO[seq(2,12,by=2), ]

    id <- which((vars$RawDataFilter[[1]]$Included==TRUE)&(vars$RawDataFilter[[2]]$Included==TRUE))
    SVO.index <- plyr::ldply(seq_along(id), function(s){cbind(uID = id[s], SVO = atan(
        (mean(SVO.other[array(c(1:6,unlist(vars$SVO[s, ])),dim=c(6,2))])-50)/
            (mean( SVO.self[array(c(1:6,unlist(vars$SVO[s, ])),dim=c(6,2))])-50)))}
    )

    #vars$SVO$Siblings <- vars$SVO$van.p2.1_1_TEXT+vars$SVO$van.p2.1_2_TEXT
    SVO.siblings <- cbind.data.frame(uID     = id,
                                     Older   = as.numeric(vars$RawDataFilter[[2]]$van.p2.1_1_TEXT[id]),
                                     Younger = as.numeric(vars$RawDataFilter[[2]]$van.p2.1_2_TEXT[id])
                                     )

    if(!all(SVO.index$uID==SVO.siblings$uID)){disp(paste("van.Lange.1: uID mismatch in", vars$RawDataFilter[[2]]$.id[1]))}

    SVO.siblings$Total <- rowSums(SVO.siblings[c('Younger','Older')])

    return(list(SVO.index = SVO.index$SVO,
                Siblings  = SVO.siblings$Total,
                N         = c(nrow(SVO.index),NULL))
           )
}

#' varfun.Hauser.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} Subjects will be excluded from all analyses if they take fewer than four
#' seconds to read and respond to either of the target scenarios. For the key confirmatory test
#' comparing with the original effect size, we will include only participants that indicate having no
#' prior experience with the task. The original authors suggested the effect may be weaker in
#' participants with prior exposure. Prior exposure will be investigated as a moderator for the other
#' analyses. A two-way contingency table will be built with Scenario (Means vs. Side-effect) and
#' Response (Yes vs. No) as factors. The critical replication hypothesis will be given by a one tailed
#' chi square test and the effect size by an odds ratio.
#'
#' @section Variables:
#'   haus1.1t = timing (side effect scenario);
#'   haus2.1t = timing (greater good scenario);
#'   haus1.2=previous experience (drop if 1 (yes));
#'   haus2.2=previous experience (drop if 1 (yes));
#'   haus1.1=morally permissible (side effect scenario; Yes=1);
#'   haus2.1=morally permissible (greater good scenario; Yes=1).
#'
#'
#' @examples
varfun.Hauser.1 <- function(vars){
    SE <- unlist(vars$SideEffect[names(vars$SideEffect)[[1]]])
    GG <- unlist(vars$GreaterGood[names(vars$GreaterGood)[[1]]])
    N  <- c(nrow(vars$SideEffect),nrow(vars$GreaterGood))

    return(list(Response = factor(c(SE ,GG),levels=c(1,2),labels=vars$labels$Response),
                Condition = factor(c(rep(1,N[1]),rep(2,N[2])),levels=c(1,2),labels=vars$labels$Condition),
                N = N)
    )
}

# #' varfun.Hauser.2
# #'
# #' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
# #'
# #' @return
# #' @export
# #'
# #' @details \strong{Analysis plan:} Participants will be excluded from all analyses if they take fewer than four seconds to read and respond to either of the target scenarios. For the key confirmatory test comparing with the original effect size, we will include only participants that indicate having no prior experience with the task. The original authors suggested the effect may be weaker in participants with prior exposure. Prior exposure will be investigated as a moderator for the other analyses.
# #'
# #' A two-way contingency table will be built with Scenario (Greater Good vs. Foreseen Side-effect) and Response (Yes vs. No) as factors. The critical replication hypothesis will be given by a one tailed chi square test and the effect size by an odds ratio.
# #'
# #' @examples
# varfun.Hauser.2 <- function(vars){
#   N = c(nrow(vars$SideEffect),nrow(vars$GreaterGood))
#   return(list(Response = factor(c(vars$SideEffect$haus1.1,vars$GreaterGood$haus2.1),levels=c(1,2),labels=vars$labels$Response),
#               Condition = factor(c(rep(1,N[1]),rep(2,N[2])),levels=c(1,2),labels=vars$labels$Condition),
#               N = N)
#   )
# }

#' varfun.Anderson.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details  \strong{Analysis plan}: Following the original authors, the three dependent measures will be
#' standardized and averaged into a single index of subjective well-being. The mean difference in
#' subjective well-being between high and low-sociometric status conditions will be tested with an
#' independent-samples t-test. All participants with data will be included in the analysis.
#'
#'
#' we computed a single subjective well-being score (SWB) by
#' standardising
#' then adding positive affect (alpha.0.84) and
#' life-satisfaction (alpha.0.84) and
#' subtracting the standardised negative affect variable (alpha.88).
#'
#'
#' @section Variables:
#' and1.3=Satisfaction With Life Scale (SWLS, 5 items, Low SocioMetricStatus condition), higher numbers=higher satisfaction; and1.4=Positive And Negative Affect Scale (PANAS, Low SocioMetricStatus condition).
#' Positive items are 1,4,5,8,9,12,14,17,18,19. Negative items: 2,3,6,7,10,11,13,15,16,20;
#' Alert: recode responses to negative items before averaging.
#' and2.3=Satisfaction With Life Scale (SWLS, 5 items, High SocioMetricStatus condition), higher numbers=higher satisfaction; and2.4=Positive And Negative
#'
#' Affect Scale (PANAS, High SocioMetricStatus condition). Positive items are 1,4,5,8,9,12,14,17,18,19.
#' Negative items: 2,3,6,7,10,11,13,15,16,20;
#' Alert: recode responses to negative items before averaging.
#'
#'list(Low=c("and1.3_1", "and1.3_2", "and1.3_3", "and1.3_4", "and1.3_5", "and1.4_1", "and1.4_2", "and1.4_3", "and1.4_4", "and1.4_5", "and1.4_6", "and1.4_7", "and1.4_8", "and1.4_9", "and1.4_10", "and1.4_11", "and1.4_12", "and1.4_13", "and1.4_14", "and1.4_15", "and1.4_16", "and1.4_17", "and1.4_18", "and1.4_19", "and1.4_20"),
#' High=c("and2.3_1", "and2.3_2", "and2.3_3", "and2.3_4", "and2.3_5", "and2.4_1", "and2.4_2", "and2.4_3", "and2.4_4", "and2.4_5", "and2.4_6", "and2.4_7", "and2.4_8", "and2.4_9", "and2.4_10", "and2.4_11", "and2.4_12", "and2.4_13", "and2.4_14", "and2.4_15", "and2.4_16", "and2.4_17", "and2.4_18", "and2.4_19", "and2.4_20"))
#'
#' @examples
varfun.Anderson.1 <- function(vars){
#    require(dplyr)

    # Negative
    PANASlowNA   <- dplyr::select(vars$Low,
                                  one_of(unlist(strsplit(paste0("and1.4_",c(2,3,6,7,10,11,13,15,16,20),sep="|"),"|",fixed=T))))
    # Negative Recode
    PANASlowNAr  <- 6-PANASlowNA
    # Positive
    PANASlowPA   <- dplyr::select(vars$Low,
                                  one_of(unlist(strsplit(paste0("and1.4_",c(1,4,5,8,9,12,14,17,18,19),sep="|"),"|",fixed=T))))
    # SWSL
    SWLSlow  <-  dplyr::select(vars$Low,
                               one_of(c("and1.3_1", "and1.3_2", "and1.3_3", "and1.3_4", "and1.3_5")))

    # Negative
    PANAShighNA  <- dplyr::select(vars$High,
                                  one_of(unlist(strsplit(paste0("and2.4_",c(2,3,6,7,10,11,13,15,16,20),sep="|"),"|",fixed=T))))
    # Negative Recode
    PANAShighNAr <- 6-PANAShighNA
    # Positive
    PANAShighPA  <- dplyr::select(vars$High,
                                  one_of(unlist(strsplit(paste0("and2.4_",c(1,4,5,8,9,12,14,17,18,19),sep="|"),"|",fixed=T))))
    # SWSL
    SWLShigh     <- dplyr::select(vars$High,
                                  one_of(c("and2.3_1", "and2.3_2", "and2.3_3", "and2.3_4", "and2.3_5")))

    # Descriptives
    MhighlowNA  <- scale(c(rowMeans(PANAShighNA), rowMeans(PANASlowNA)))
    MhighlowNAr <- scale(c(rowMeans(PANAShighNAr), rowMeans(PANASlowNAr)))
    MhighlowPA  <- scale(c(rowMeans(PANAShighPA), rowMeans(PANASlowPA)))
    MhighlowSW  <- scale(c(rowMeans(SWLShigh),rowMeans(SWLSlow)))


    # MhighNA <- scale(rowMeans(PANAShighNA))
    # MhighNAr <- scale(rowMeans(PANAShighNAr))
    # MhighPA  <- scale(rowMeans(PANAShighPA))
    # MhighSW  <- scale(rowMeans(SWLShigh))
    #
    # MlowNA  <- scale(rowMeans(PANASlowNA))
    # MlowNAr <- scale(rowMeans(PANASlowNAr))
    # MlowPA  <- scale(rowMeans(PANASlowPA))
    # MlowSW  <- scale(rowMeans(SWLSlow))

   # [mean(std(SWLS), std(PA), std(-NA)].
   # [std(SWLS) + std(PA)- std(NA)].


    return(list(SWB        = (MhighlowSW + MhighlowPA + MhighlowNAr)/3,
                Condition = factor(c(rep("High",nrow(PANAShighPA)),rep("Low",nrow(PANASlowPA)))),
                N    = c(nrow(PANAShighPA), nrow(PANASlowPA)))
           )
}

#' varfun.Ross.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details     \strong{Analysis plan:} An independent samples t-test will be conducted with participants' choice
#' (sign release/refuse to sign) as the IV and participant estimate of % of peers who would sign the
#' release as the DV.
#'
#' Note that participants self-select whether to sign or refuse to sign the release, so it is not random assignment to levels of the independent variable.
#' Participants will be included in the analysis if they respond to all three questions and their estimate for the DV (e.g., 'what percent of your peers would sign the release') falls between 0-100
#'
#' @section Variables:
#' ross.s1.1 = percentage of peers;
#' ross.s1.2 = you; values: 1=sign; 2=refuse
#'
#' @examples
varfun.Ross.1 <- function(vars){
    return(list(Peers  = vars$Peers[[1]],
                You    = factor(vars$You[[1]],levels=c(1,2),labels=vars$labels$Response),
                N      = c(sum(vars$You[[1]]==1),sum(vars$You[[1]]==2)))
    )
}

#' varfun.Ross.2
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} An independent samples t-test will be conducted with participants' choice (sign release/refuse to sign) as the IV and participant estimate of % of peers who would sign the release as the DV. Note that participants self-select whether to sign or refuse to sign the release.
#' Not random assignment to levels of the independent variable.
#'
#' Participants will be included in the analysis if they respond to all three questions and their estimate for the DV (e.g., 'what
#' percent of your peers would sign the release') falls between 0-100
#'
#' @section Variables:
#' ross.s2.1=percentage of peers;
#' ross.s2.2=you; values: 1=Pay; 2=Appear in court
#'
#' @examples
varfun.Ross.2 <- function(vars){
    return(list(Peers  = vars$Peers[[1]],
                You    = factor(vars$You[[1]],levels=c(1,2),labels=vars$labels$Response),
                N      = c(sum(vars$You[[1]]==1),sum(vars$You[[1]]==2)))
    )
}

#' varfun.Giessner.1
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} Responses to the five dependent measures will be averaged and an independent samples
#' t-test will compare mean power rating between the 2 cm and 7 cm conditions.
#' All participants who complete at least one item of the dependent measure will be  included in the analysis.
#'
#' @section Variables:
#' geis.1.1=long line condition;
#' geis.2.1=short line condition;
#' geis.dv_1=dominant;
#' geis.dv_2=strong;
#' geis.dv_3=self-confident;
#' geis.dv_4=control;
#' geis.dv_5=status;
#' For all dvs, higher numbers=higher power.
#'
#' @examples
varfun.Giessner.1 <- function(vars){
#    require(dplyr)

    Long <- vars$Long  %>% dplyr::filter(!is.na(vars$Long[1])  & rowSums(!is.na(vars$Long[-1, ]))>1)
    Short<- vars$Short %>% dplyr::filter(!is.na(vars$Short[1]) & rowSums(!is.na(vars$Short[-1, ]))>1)

    return(list(Long   = rowMeans(Long[-1]),
                Short  = rowMeans(Short[-1]),
                N      = c(nrow(Long),nrow(Short)))
    )
}

#' varfun.Tversky.1
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @references    Tversky, A., Kahneman, D. (1981). The framing of decisions and the psychology of choice. Science, 211, 453-458.
#'
#' @details  \strong{Analysis plan:} A two-way contingency table will be built with Price condition ($20 vs. $240) and Response (Yes vs. No) as factors.
#' The critical replication hypothesis will be given by a X22 test and the effect size by an odds ratio.
#' All participants with valid responses will be included in analysis.
#'
#' @section Variables:
#' tver1.1=choice ($250 wall hanging condition, yes=1, no=2);
#' tver2.1=choice ($30 wall hanging cond, yes=1, no=2).
#'
#' Materials and procedure. Participants will receive one of two scenarios from the original with dollar amounts approximately adjusted for inflation and the consumer items being replaced with a ceramic vase and a wall hanging.
#'
#' tver1.1 Imagine that you are about to purchase a ceramic vase for $30, and a wall hanging for $250. The salesman informs you that the wall hanging you wish to buy is on sale for $240 at the other branch of the store, located 20 minutes drive away. Would you make the trip to the other store?
#' m  Yes, I would go to the other branch. (1)
#' m  No, I would not go to the other branch. (2)
#'
#' tver2.1 Imagine that you are about to purchase a ceramic vase for $250, and a wall hanging for $30. The salesman informs you that the wall hanging you wish to buy is on sale for $20 at the other branch of the store, located 20 minutes drive away. Would you make the trip to the other store?
#' m  Yes, I would go to the other branch. (1)
#' m  No, I would not go to the other branch. (2)
#'
#' Materials here: https://osf.io/8t9ha/. Test the study here: https://ufl.qualtrics.com/SE/?SID=SV_aW8rIyGPNQ2Wwh7.
#'
#' @examples
varfun.Tversky.1 <- function(vars){
    return(list(Condition = factor(c(rep(1,nrow(vars$Cheap)),rep(2,nrow(vars$Expensive))),levels=c(1,2),labels=vars$labels$Condition),
                Response  = factor(c(vars$Cheap[[1]],vars$Expensive[[1]]),levels=c(1,2),labels=vars$labels$Response),
                N         = c(nrow(vars$Cheap),nrow(vars$Expensive)))
           )
}

#' varfun.Hauser.2
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis Plan:} Participants will be excluded from all analyses if they take fewer than four seconds to read and respond to either of the target scenarios.
#'   For the key confirmatory test comparing with the original effect size, we will include only participants that indicate having no prior experience with the task.
#'   Prior exposure will be investigated as a moderator for the other analyses
#'
#'
#' @section Variables:
#' hauser3.1=morality judgment (greater good condition);
#' hauser4.1=morality judgment (foreseen side-effect condition; for both, yes=1, no=2.)
#' haus3.2 and haus4.2=previous experience (yes=1, no=2);
#' haus3.1t_3=timing (greater good);
#' haus4.1t_3=timing (side effect).
#'
#' @references Hauser, M., Cushman, F., Young, L., Kang-Xing Jin, R., & Mikhail, J. (2007). A dissociation between moral judgments and justifications. Mind & Language, 22, 1-21.
#'
#' @examples
varfun.Hauser.2 <- function(vars){
    SideEffect  <- dplyr::filter(vars$SideEffect, vars$SideEffect[vars$labels$Experience[1]] !=1 & vars$SideEffect[vars$labels$Timing[1]]>4)
    GreaterGood <- dplyr::filter(vars$GreaterGood,vars$GreaterGood[vars$labels$Experience[2]]!=1 & vars$GreaterGood[vars$labels$Timing[2]]>4)
    N <- c(nrow(SideEffect),nrow(GreaterGood))

    return(list(Response  = factor(c(SideEffect$haus3.1,GreaterGood$haus4.1),levels=c(1,2),labels=vars$labels$Response),
                Condition = factor(c(rep(1,N[1]),rep(2,N[2])),levels=c(1,2),labels=vars$labels$Condition),
                N = N)
    )
}

#' varfun.Risen.1
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @references  Risen, J. L., & Gilovich, T. (2008). Why people are reluctant to tempt fate. \strong{Journal of Personality and Social Psychology}, 95, 293.
#'
#' @details \strong{Analysis plan:} The two groups will be compared with an independent samples t-test. All participants that answer the dependent measure will be included in analysis.  The primary confirmatory test for comparing the original and replication effect size will be based on only the samples using undergraduate students. We will examine gender as a possible moderator of the effect in a supplemental, exploratory analysis. All participants that answer the dependent measure will be included in analysis. The primary confirmatory test for comparing the original and replication effect size will be based on only the samples using undergraduate students.
#'
#'
#'
#' @section Variables:
#' rise1.3=likelihood that the professor will call on you (unprepared condition);
#' rise2.3=likelihood that the professor will call on you (prepared condition);
#' for both, higher numbers=higher likelihood
#' Variable = "ex.subjp" which asked if participants were recruited through a university subject pool. 1 = yes, 2 = no.
#'
#' @export
#'
#' @examples
varfun.Risen.1 <- function(vars){
    return(list(Unprepared  = as.numeric(vars$Unprepared[[1]]),
                Prepared    = as.numeric(vars$Prepared[[1]]),
                N           = c(nrow(vars$Unprepared),nrow(vars$Prepared)))
           )
}


#' varfun.Risen.2
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} The two groups will be compared with an independent samples t-test. All participants that answer the dependent measure will be included in analysis.
#'  The primary confirmatory test for comparing the original and replication effect size will be based on only the samples using undergraduate students.
#'  We will examine gender as a possible moderator of the effect in a supplemental, exploratory analysis.
#'  use variable "sex" 1 = male, 2 = female. (3 = other and 4 = prefer not to answer, which I think we probably do not use for this analysis)
#'
#' @section Variables:
#' rise1.3=likelihood that the professor will call on you (unprepared condition);
#' rise2.3=likelihood that the professor will call on you (prepared condition);
#'
#' for both, higher numbers=higher likelihood   All participants that answer the dependent measure will be included in analysis.
#' The primary confirmatory test for comparing the original and replication effect size will be based on only the samples using undergraduate students.
#'
#' @references  Risen, J. L., & Gilovich, T. (2008). Why people are reluctant to tempt fate. Journal of Personality and Social Psychology, 95, 293.
#'
#' @examples
varfun.Risen.2 <- function(vars){
      return(list(Likelihood = c(vars$Unprepared$rise1.3,vars$Prepared$rise2.3),
                Condition  = factor(c(rep(1,nrow(vars$Unprepared)),rep(2,nrow(vars$Prepared))),levels=c(1,2),labels=vars$labels$Condition),
                Gender     = factor(c(vars$Unprepared$sex,vars$Prepared$sex)),
                N          = c(nrow(vars$Unprepared),nrow(vars$Prepared)))
    )
}

#' varfun.Savani.1
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @details \strong{Analysis plan:} We will conduct a hierarchical logistic regression analysis with Choice (binary) as the dependent variable, the Importance of decision (ordered categorical) as a trial-level covariate nested within participants, and Condition (categorical) as a participant-level factor indicating whether a participant was in the personal or interpersonal condition.  The effect of interest will be the odds of construing an action as a choice, depending on the condition a participant was in, controlling for the reported importance of the action.
#'
#' Because some survey questions may be less suitable for non-student samples, we will only include university data collections in the primary confirmatory analysis to be compared with the original effect sizes. Data for all participants will be included to examine variability across sample and setting. However, participants must respond to all choice and importance of choice questions to be included in the analysis. The target effect size for replication will be the the results obtained for participants from labs in India, to compare to the effect found in the Indian sample in the original (Indian participants were more likely to construe interpersonal actions as choices than personal actions). Although we only have few labs from India, we are making extra efforts to recruit many participants in those labs. We anticipate that this effect will vary by sample, particularly in line with the original demonstration of cultural differences.
#'
#' @section Variables:
#' sava1.N=interpersonal actions;
#'
#' sava2.N=personal actions;
#'
#' 'sava1.4', 'sava1.5', 'sava1.9', 'sava1.10', 'sava1.15', 'sava1.16' , 'sava1.21', 'sava1.22', 'sava1.27', 'sava1.28', 'sava1.33', 'sava1.34',  'sava1.38', 'sava1.39', 'sava1.43', 'sava1.44'
#'
#' sava1.4=choice (buy a gift; 1=choice; 2=no choice);
#'
#' sava1.5=importance (buy a gift);
#'
#' sava1.9=choice (take a friend at the restaurant; 1=choice; 2=no choice);
#'
#' sava1.10=importance (restaurant);
#'
#' sava1.15=choice (trip; 1=choice, 2 and 3 = no choice);
#'
#' sava1.16=importance (trip);
#'
#' sava1.21=choice (dinner; 1=choice, 2 and 3 = no choice);
#'
#' sava1.22=importance (dinner);
#'
#' sava1.27=choice (errand; 1=choice, 2 and 3 = no choice);
#'
#' sava1.28=importance (errand);
#'
#' sava1.33=choice (help, 1=choice, 2 & 3 = no choice);
#'
#' sava1.34=importance (help);
#'
#' sava1.38=choice (advice, 1=choice, 2 & 3 = no choice);
#'
#' sava1.39=importance (advice);
#'
#' sava1.43=choice (friends, 1=choice, 2 & 3 = no choice);
#'
#' sava1.44=importance (friends);
#'
#'
#' sava2.4=choice (buy for yourself; 1=choice; 2=no choice);
#'
#' sava2.5=importance (buy for yourself);
#'
#' sava2.9=choice (at the restaurant by yourself; 1=choice; 2=no choice);
#'
#' sava2.10=importance (restaurant by yourself);
#'
#' sava2.15=choice (trip alone; 1=choice, 2 and 3 = no choice);
#'
#' sava2.16=importance (trip alone);
#'
#' sava2.21=choice (out for dinner; 1=choice, 2 and 3 = no choice);
#'
#' sava2.22=importance (out for dinner);
#'
#' sava2.27=choice (errand for yourself; 1=choice, 2 and 3 = no choice);
#'
#' sava2.28=importance (errand for yourself);
#'
#' sava2.33=choice (ask for help, 1=choice, 2 & 3 = no choice);
#'
#' sava2.34=importance (ask for help);
#'
#' sava2.38=choice (take a course, 1=choice, 2 & 3 = no choice);
#'
#' sava2.39=importance (take a course);
#'
#' sava2.43=choice (friends, 1=choice, 2 & 3 = no choice);
#'
#' sava2.44=importance (friends);
#'
#'
#' For all importance items: higher numbers=higher importance
#'
#' we will only include university data collections in the primary confirmatory analysis to be compared with the original effect sizes.
#'
#' Data for all participants will be included to examine variability across sample and setting.
#' However, participants must respond to all choice and importance of choice questions to be included in the analysis.
#'
#' @return
#' @export
#'
#' @examples
varfun.Savani.1 <- function(vars){
#     require(reshape2)
#     require(dplyr)

    choice.Int     <- c('sava1.4', 'sava1.9', 'sava1.15', 'sava1.21', 'sava1.27', 'sava1.33', 'sava1.38', 'sava1.43')
    importance.Int <- c('sava1.5', 'sava1.10', 'sava1.16', 'sava1.22', 'sava1.28', 'sava1.34', 'sava1.39', 'sava1.44')

    choice.Pers     <- c('sava2.4', 'sava2.9', 'sava2.15', 'sava2.21', 'sava2.27', 'sava2.33', 'sava2.38', 'sava2.43')
    importance.Pers <- c('sava2.5','sava2.10', 'sava2.16', 'sava2.22', 'sava2.28','sava2.34', 'sava2.39', 'sava2.44')

    Response             <- rbind(dplyr::select(vars$Interpersonal,Choice=one_of(choice.Int)),
                                  dplyr::select(vars$Personal,Choice=one_of(choice.Pers))
                                  )
    Condition    <- factor(c(rep(1,nrow(vars$Interpersonal)),rep(2,nrow(vars$Personal))),levels=c(1,2),labels=vars$labels$Condition)
    id           <- seq_along(Condition)

    Response[Response>1] <- 0
    Response$Condition   <- Condition
    Response$uID         <- id
    Response             <- reshape2::melt(Response, id = c('uID','Condition'), variable.name = 'trialID', value.name = 'Response')
    #Response$Response    <- factor(Response$Response, levels = c(0,1), labels = vars$labels$Response)
    #Response$Response    <- relevel(Response$Response, vars$labels$Response[[1]])

    Importance           <- rbind(dplyr::select(vars$Interpersonal, Importance = one_of(importance.Int)),
                                  dplyr::select(vars$Personal, Importance = one_of(importance.Pers))
                                  )
    Importance$uID       <- id
    Importance$Condition <- Condition
    Importance           <- reshape2::melt(Importance, id = c('uID','Condition'), variable.name = 'VarLabel',
                                           value.name = 'Importance')
    # Probably superfluous
    matchID              <- Response$uID == Importance$uID
    Response$Importance[matchID] <- scale(Importance$Importance[matchID],scale=FALSE)

    return(list(Response   = Response$Response,
                Condition  = Response$Condition,
                Importance = Response$Importance,
                uID        = Response$uID,
                trialID    = as.numeric(Response$trialID),
                df         = tbl_df(Response),
                N          = c(nrow(vars$Interpersonal),nrow(vars$Personal)))
           )
}



#' varfun.Norenzayan.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @details \strong{Analysis plan:} We will compute for each subject the percentage of rule-based responses and test whether the mean of the two experimental groups (belong vs similar) on this DV is equal with a t-test for independent samples.
#'  The effect size will be given by a standardized mean difference. All participants with data will be included in analysis.
#'
#' For additional analysis, a few items about cultural origins of participants and their parents are present in the individual differences assessment.
#'   These could be particularly useful for follow-up moderator analysis.
#'
#' @section Variables:
#'  nore1.1 TO nore1.20 provide choices ("belong to" condition)
#'
#'  nore2.1 to nore2.20 provide choices ("similar to" condition)
#'
#' @return
#'
#' @export
#'
#' @references  Norenzayan, A., Smith, E. E., Kim, B. J., & Nisbett, R. E. (2002). Cultural preferences for formal versus intuitive reasoning. Cognitive Science, 26, 653-684.
#'
#' @examples
varfun.Norenzayan.1 <- function(vars){
    return(list(Belong  = rowMeans(vars$Belong==rep(1:2,10),na.rm=TRUE),
                Similar = rowMeans(vars$Similar==rep(1:2,10),na.rm=TRUE),
                N       = c(nrow(vars$Belong), nrow(vars$Similar)))
           )
}

#' varfun.Norenzayan.2
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @details   \strong{Analysis plan:} We will compute for each subject the percentage of rule-based responses and test whether the mean of the two experimental groups (belong vs similar) on this DV is equal with a t-test for independent samples.
#' The effect size will be given by a standardized mean difference.
#' All participants with data will be included in analysis.
#'
#' @note This analysis tests moderating effect of presenting Gati first or after.
#'
#' @export
#'
#' @references  Norenzayan, A., Smith, E. E., Kim, B. J., & Nisbett, R. E. (2002). Cultural preferences for formal versus intuitive reasoning. Cognitive Science, 26, 653-684.
#' @examples
varfun.Norenzayan.2 <- function(vars){

    NafterTG.Bel <- sapply(which((vars$RawDataFilter[[1]]$Included)), function(i) which(unlist(strsplit(x = vars$RawDataFilter[[1]]$StudyOrderN[i], split = "[|]")) == "Norenzayan") > which(unlist(strsplit(x = vars$RawDataFilter[[1]]$StudyOrderN[i], split = "[|]")) == "Tversky.Gati"))
    NafterTG.Sim <- sapply(which((vars$RawDataFilter[[2]]$Included)), function(i) which(unlist(strsplit(x = vars$RawDataFilter[[2]]$StudyOrderN[i], split = "[|]")) == "Norenzayan") > which(unlist(strsplit(x = vars$RawDataFilter[[2]]$StudyOrderN[i], split = "[|]")) == "Tversky.Gati"))
    length(rowSums(vars$Similar[,1:20]==1,na.rm=TRUE)/20)

    NafterTG.Bel <- unlist(NafterTG.Bel)
    NafterTG.Sim <- unlist(NafterTG.Sim)

    N = c(length(NafterTG.Bel),length(NafterTG.Sim))

    return(list(Response  = c(rowSums(vars$Belong==rep(1:2,10),na.rm=T)/20, rowSums(vars$Similar==rep(1:2,10),na.rm=T)/20),
                Condition = factor(c(rep(1,N[1]),rep(2,N[2])),levels=c(1,2),labels=vars$labels$Condition),
                Order     = factor(c(as.numeric(NafterTG.Bel), as.numeric(NafterTG.Sim)), levels=c(0,1), labels = vars$labels$Order),
                uID       = 1:(sum(N,na.rm = TRUE)),
                N         = N))
}

#' varfun.Hsee.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details \strong{Analysis plan:} The two conditions will be compared with an independent samples t-test with rated generosity of gift giver as the dependent variable.
#' All participants with data will be included in the analysis.
#'
#' @section Variables:
#' hsee1.1=generosity ($90 scarf condition);
#' hsee2.1=generosity ($110 coat condition);
#' for both, higher numbers=higher generosity
#'
#' @references Hsee, C. K. (1998). Less is better: When low-value options are valued more highly than high-value options. Journal of Behavioral Decision Making, 11, 107-121.
#'
#' @examples
varfun.Hsee.1 <- function(vars){
    return(list(Scarf  = as.numeric(vars$Scarf[[1]]),
                Coat   = as.numeric(vars$Coat[[1]]),
                N      = c(length(as.numeric(vars$Scarf[[1]])),length(as.numeric(vars$Coat[[1]]))))
           )
}

#' varfun.Gray.1
#'
#' @param vars A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @references Gray, K., & Wegner, D. M. (2009). Moral typecasting: divergent perceptions of moral agents and moral patients. Journal of Personality and Social Psychology, 96, 505.
#'
#' @details \strong{Analysis plan:} We will compare the means on perceived responsibility between conditions with an independent samples t-test for the responsibility item.
#' The intentionality item will be analyzed the same way as a secondary analysis.
#' All participants with data will be included in analysis.
#'
#' @section Variables:
#'
#' Adult harms baby scenario; gray1.2=responsibility (adult);  gray1.4=pain (baby).
#' Baby harms adult scenario; gray2.2=responsibility (baby);  gray2.4=pain (adult)
#'
#' @examples
varfun.Gray.1 <- function(vars){
    return(list(adultHbaby = as.numeric(vars$adultHbaby[[1]]),
                babyHadult = as.numeric(vars$babyHadult[[1]]),
                N     = c(length(as.numeric(vars$adultHbaby[[1]])),length(as.numeric(vars$babyHadult[[1]]))))
    )
}

#' varfun.Gray.2
#'
#' @param vars A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @references Gray, K., & Wegner, D. M. (2009). Moral typecasting: divergent perceptions of moral agents and moral patients. Journal of Personality and Social Psychology, 96, 505.
#'
#' @details \strong{Analysis plan:} We will compare the means on perceived responsibility between conditions with an independent samples t-test for the responsibility item.
#' The intentionality item will be analyzed the same way as a secondary analysis.
#' All participants with data will be included in analysis.
#'
#' @section Variables:
#' Baby harms adult scenario; gray1.3=intentionality (adult); gray1.4=pain (baby).
#' Adult harms baby scenario; gray2.3=intentionality (baby); gray2.4=pain (adult)
#'
#' @examples
varfun.Gray.2 <- function(vars){
    return(list(adultHbaby = as.numeric(vars$adultHbaby[[1]]),
                babyHadult = as.numeric(vars$babyHadult[[1]]),
                N     = c(length(as.numeric(vars$adultHbaby[[1]])),length(as.numeric(vars$babyHadult[[1]])))))
}

#' varfun.Zhong.1
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @references Zhong, C. B., & Liljenquist, K. (2006). Washing away your sins: Threatened morality and physical cleansing. Science, 313, 1451???1452.
#'
#' @details  \strong{Analysis plan:} The key factor of interest is whether condition affects ratings of the cleaning products, so ratings of the five cleaning products will be averaged and compared between the two conditions (ethical or unethical) with an independent samples t-test.
#'
#' A second comparison is whether there is a condition difference between ratings of the other products. The theoretical expectation is that this difference will be weak or near zero. This will be examined as a secondary analysis as a 2 (ethical-unethical) x 2 (cleaning-other products) mixed model ANOVA, and a follow-up independent samples t-test comparing ratings of other products between the ethical and unethical conditions.3
#'
#' Participants who copy less than half the target article will be excluded from analysis.
#'
#' @section Variables:
#' zhon1.1= unethical condition;
#' zhon2.1=ethical condition;
#'
#' zhon.dv.1_1 TO zhon.dv.1_10=desirability of products (both conditions);
#' higher numbers=higher desirability;
#'
#' Products list:
#'
#' Clean:
#' Dove shower soap (zhon.dv.1_2),
#' Crest toothpaste (zhon.dv.1_3),
#' Windex glass cleaner (zhon.dv.1_7),
#' Lysol countertop disinfectant (zhon.dv.1_8),
#' Tide laundry detergent (zhon.dv.1_10)
#'
#' Not-clean:
#' Post-it notes (zhon.dv.1_1),
#' Nantucket Nectars juice (zhon.dv.1_4),
#' Energizer batteries (zhon.dv.1_5),
#' Sony cd cases (zhon.dv.1_6),
#' Snickers candy bar (zhon.dv.1_9),
#'
#' @examples
varfun.Zhong.1 <- function(vars){
  # First column is nCopied
   idClean <- c(2,3,7,8,10)+1
   idOther <- c(1,4,5,6,9)+1

    return(list(Ethical   = rowMeans(vars$Ethical[ ,idClean],na.rm = TRUE),
                Unethical = rowMeans(vars$Unethical[ ,idClean], na.rm = TRUE),
                N         = c(length(rowMeans(vars$Ethical[ ,idClean],na.rm = TRUE)), length(rowMeans(vars$Unethical[ ,idClean], na.rm = TRUE))))
           )
}

#' varfun.Zhong.2
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @references Zhong, C. B., & Liljenquist, K. (2006). Washing away your sins: Threatened morality and physical cleansing. Science, 313, 1451???1452.
#'
#' @details  \strong{Analysis plan:} The key factor of interest is whether condition affects ratings of the cleaning products, so ratings of the five cleaning products will be averaged and compared between the two conditions (ethical or unethical) with an independent samples t-test.
#'
#' A second comparison is whether there is a condition difference between ratings of the other products. The theoretical expectation is that this difference will be weak or near zero. This will be examined as a **secondary analysis as a 2 (ethical-unethical) x 2 (cleaning-other products) mixed model ANOVA**, and a follow-up independent samples t-test comparing ratings of other products between the ethical and unethical conditions.3
#'
#' Participants who copy less than half the target article will be excluded from analysis.
#'
#' @section Variables:
#' zhon1.1= unethical condition;
#' zhon2.1=ethical condition;
#'
#' zhon.dv.1_1 TO zhon.dv.1_10=desirability of products (both conditions);
#' higher numbers=higher desirability;
#'
#' Products list:
#'
#' Clean:
#' Dove shower soap (zhon.dv.1_2),
#' Crest toothpaste (zhon.dv.1_3),
#' Windex glass cleaner (zhon.dv.1_7),
#' Lysol countertop disinfectant (zhon.dv.1_8),
#' Tide laundry detergent (zhon.dv.1_10)
#'
#' Not-clean:
#' Post-it notes (zhon.dv.1_1),
#' Nantucket Nectars juice (zhon.dv.1_4),
#' Energizer batteries (zhon.dv.1_5),
#' Sony cd cases (zhon.dv.1_6),
#' Snickers candy bar (zhon.dv.1_9),
#'
#' @examples
varfun.Zhong.2 <- function(vars){
    #in.IT(c('lme4','lmerTest'))

    idClean <- c(2,3,7,8,10)+1
    idOther <- c(1,4,5,6,9)+1

    return(list(Response  = c(rowMeans(vars$Ethical[,idClean]),
                              rowMeans(vars$Ethical[,idOther]),
                              rowMeans(vars$Unethical[,idClean]),
                              rowMeans(vars$Unethical[,idOther])
                              ),
                Condition = factor(c(rep(1,times=nrow(vars$Ethical)),
                                     rep(1,times=nrow(vars$Ethical)),
                                     rep(2,times=nrow(vars$Unethical)),
                                     rep(2,times=nrow(vars$Unethical))
                                     ), levels=c(1,2),labels=vars$labels$Condition
                                   ),
                Product   = factor(c(rep(1,times=nrow(vars$Ethical)),
                                     rep(2,times=nrow(vars$Ethical)),
                                     rep(1,times=nrow(vars$Unethical)),
                                     rep(2,times=nrow(vars$Unethical))
                                     ), levels=c(1,2),labels=vars$labels$Product
                                   ),
                uID       = c(seq_along(vars$Ethical[[1]]),
                              seq_along(vars$Ethical[[1]]),
                              max(seq_along(vars$Ethical[[1]])) + seq_along(vars$Unethical[[1]]),
                              max(seq_along(vars$Ethical[[1]])) + seq_along(vars$Unethical[[1]])
                              ),
                N         = c(nrow(vars$Ethical),nrow(vars$Unethical)))
           )
}

#' varfun.Zhong.3
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @references Zhong, C. B., & Liljenquist, K. (2006). Washing away your sins: Threatened morality and physical cleansing. Science, 313, 1451???1452.
#'
#' @details  \strong{Analysis plan:} The key factor of interest is whether condition affects ratings of the cleaning products, so ratings of the five cleaning products will be averaged and compared between the two conditions (ethical or unethical) with an independent samples t-test.
#'
#' A second comparison is whether there is a condition difference between ratings of the other products. The theoretical expectation is that this difference will be weak or near zero. This will be examined as a secondary analysis as a 2 (ethical-unethical) x 2 (cleaning-other products) mixed model ANOVA, and a follow-up **independent samples t-test comparing ratings of other products between the ethical and unethical conditions.**
#'
#' Participants who copy less than half the target article will be excluded from analysis.
#'
#' @section Variables:
#' zhon1.1= unethical condition;
#' zhon2.1=ethical condition;
#'
#' zhon.dv.1_1 TO zhon.dv.1_10=desirability of products (both conditions);
#' higher numbers=higher desirability;
#'
#' Products list:
#'
#' Clean:
#' Dove shower soap (zhon.dv.1_2),
#' Crest toothpaste (zhon.dv.1_3),
#' Windex glass cleaner (zhon.dv.1_7),
#' Lysol countertop disinfectant (zhon.dv.1_8),
#' Tide laundry detergent (zhon.dv.1_10)
#'
#' Not-clean:
#' Post-it notes (zhon.dv.1_1),
#' Nantucket Nectars juice (zhon.dv.1_4),
#' Energizer batteries (zhon.dv.1_5),
#' Sony cd cases (zhon.dv.1_6),
#' Snickers candy bar (zhon.dv.1_9),
#'
#' @examples
varfun.Zhong.3 <- function(vars){
    idClean <- c(2,3,7,8,10)+1
    idOther <- c(1,4,5,6,9)+1

    return(list(Ethical   = rowMeans(vars$Ethical[ ,idOther],na.rm = TRUE),
                Unethical = rowMeans(vars$Unethical[ ,idOther], na.rm = TRUE),
                N         = c(length(rowMeans(vars$Ethical[ ,idOther],na.rm = TRUE)),
                              length(rowMeans(vars$Unethical[ ,idOther], na.rm = TRUE))))
    )
}

#' varfun.Schwarz.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @export
#'
#' @references Schwarz, N., Strack, F., & Mai, H. P. (1991). Assimilation and contrast effects in part-whole question sequences: A conversational logic analysis. Public Opinion Quarterly, 55, 3-23.
#'
#' @details \strong{Analysis plan:} We will compute the correlation between responses to the general and specific question in each item order condition,
#' and then compare the correlations using the Fisher r-to-z transformation.
#' Participants with valid responses to both items will be included in the analysis.
#'
#' @section Variables:
#' schw1.1=life sat (first);
#' schw1.2=partner satisfaction (second);
#' schw2.1=partner satisfaction (first);
#' schw2.2=life sat (second).
#' for all, higher numbers=higher satisfaction
#'
#' @references Schwarz, N., Strack, F., & Mai, H. P. (1991). Assimilation and contrast effects in part-whole question sequences: A conversational logic analysis. \strong{Public Opinion Quarterly, 55}, 3-23.
#'
#' @examples
varfun.Schwarz.1 <- function(vars){
    return(list(r1 = cbind(vars$SpecificFirst[,1],vars$SpecificFirst[,2]),
                r2 = cbind(vars$GlobalFirst[,1],vars$GlobalFirst[,2]),
                N  = c(nrow(vars$SpecificFirst),nrow(vars$GlobalFirst)))
           )
}

#' varfun.Schwarz.2
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#'
#' @export
#'
#' @details \strong{Analysis plan:} We will compute the correlation between responses to the general and
#'  specific question in each item order condition, and then compare the correlations using
#'  the Fisher r-to-z transformation. Participants with valid responses to both items will
#'  be included in the analysis.
#'
#' @references Schwarz, N., Strack, F., & Mai, H. P. (1991). Assimilation and contrast effects in part-whole question sequences: A conversational logic analysis. \strong{Public Opinion Quarterly, 55}, 3-23.
#'
#' @examples
varfun.Schwarz.2 <- function(vars){
    id <- sapply(seq_along(vars$RawDataFilter[[1]]$.id), function(i) unlist(strsplit(x = vars$RawDataFilter[[1]]$StudyOrderN[i], split = "[|]"))[[1]] == "Schwarz")
    r1 <- na.exclude(cbind(vars$SpecificFirst[id,1], vars$SpecificFirst[id,2]))
    r2 <- na.exclude(cbind(vars$GlobalFirst[id,1], vars$GlobalFirst[id,2]))
    return(list(r1 = r1,
                r2 = r2,
                N  = c(nrow(r1),nrow(r2))
                )
           )
}

#' varfun.Shafir.1
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @references Shafir, E. (1993). Choosing versus rejecting: Why some options are both better and worse than others. Memory & Cognition, 21, 546-556.
#'
#' @details \strong{Analysis plan:} The proportion of participants awarding or denying custody for parent B
#' will be summed from both groups and tested against 100% with a Z test: mu0 = 100%, mu1 = ParentB%
#'
#' \strong{CHANGED} The analysis in the orignal article was likely as follows:
#'
#' - Count number of Parent B choices in both conditions
#' - Sum the proportions
#' - Divide by 2 and test against proportion = .5
#'
#' @section Variables:
#' shaf1.1=choice (award condition; Parent A=1, Parent B=2);
#' shaf2.1=choice (deny condition; Parent A=1, Parent B=2)
#'
#' @examples
varfun.Shafir.1 <- function(vars){
    Response = factor(c(vars$Award$shaf1.1,vars$Deny$shaf2.1), levels = c(1,2),labels = c("parent A", "Parent B"))
    N        = c(length(na.exclude(vars$Award$shaf1.1)), length(na.exclude(vars$Deny$shaf2.1)))

    return(list(Response  = Response,
                Condition = factor(c(rep("Award",N[1]), rep("Deny",N[2]))),
                ParentB   = sum(c(sum(vars$Award$shaf1.1 == 2, na.rm = TRUE) / N[1],
                                  sum(vars$Deny$shaf2.1  == 2, na.rm = TRUE) / N[2]),
                                na.rm = TRUE)/2,
                N         = N #c(nrow(vars$Award), nrow(vars$Deny))
                )
           )
    # prop.test(x = ParentB, n=sum(N), p = .5, conf.level=stat.params[[1]], alternative = stat.params[[4]])
    # prop.test(x = .6, n=170, p = .5)
}

#' varfun.Zaval.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @description \strong{Analysis plan:} Mean differences in belief and concern about global warming between heat and cold-priming conditions will be evaluated with an independent samples t-test. The scrambled sentence task could introduce unanticipated variation across translations. As such, the direct replication test will use only English language sites, and - like all other effects - all samples and settings with data will be included in analyses examining heterogeneity to see if factors, like translation, have an impact on effect estimates.
#'
#' the direct replication test will use only English language sites,
#' and - like all other effects - all samples and settings with data will be included in analyses examining heterogeneity to see if factors, like translation,
#' have an impact on effect estimates
#'
#' @section Variables:
#' zav1.1 TO zav1.13 provide COLD primes.
#' zav2.1 TO zav2.13 provide HEAT primes.
#' zav.dv.2=belief;
#' zav.dv.3=concern;
#' higher numbers=higher belief/concern.
#'
#'
#' @references Zaval, L., Keenan, E. A., Johnson, E. J., & Weber, E. U. (2014). How warm days increase belief in global warming. \strong{Nature Climate Change}, 4, 143-147.
#'
#' @examples
varfun.Zaval.1 <- function(vars){

    idC <- vars$Cold$zav.include.strict&(vars$Cold$zav.condition==1)
    idH <- vars$Heat$zav.include.strict&(vars$Heat$zav.condition==2)

    return(list(Cold = as.numeric(unlist(vars$Cold[idC,1])),
                Heat = as.numeric(unlist(vars$Heat[idH,1])),
                N    = c(length(as.numeric(unlist(vars$Cold[idC,1]))),length(as.numeric(unlist(vars$Heat[idH,1]))))
                )
           )
}

# #' varfun.Zaval.2
# #'
# #' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
# #'
# #' @return
# #' @export
# #'
# #' @description \strong{Analysis plan:} Mean differences in belief and concern about global warming between heat and cold-priming conditions will be evaluated with an independent samples t-test. The scrambled sentence task could introduce unanticipated variation across translations. As such, the direct replication test will use only English language sites, and - like all other effects - all samples and settings with data will be included in analyses examining heterogeneity to see if factors, like translation, have an impact on effect estimates.
# #'
# #' the direct replication test will use only English language sites, and - like all other effects - all samples and settings with data will be included in analyses examining heterogeneity to see if factors, like translation, have an impact on effect estimates
# #'
# #' @section Variables:
# #' zav1.1 TO zav1.13 provide COLD primes.
# #' zav2.1 TO zav2.13 provide HEAT primes.
# #' zav.dv.2=belief;
# #' zav.dv.3=concern;
# #' higher numbers=higher belief/concern.
# #'
# #' @references Zaval, L., Keenan, E. A., Johnson, E. J., & Weber, E. U. (2014). How warm days increase belief in global warming. \strong{Nature Climate Change}, 4, 143-147.
# #'
# #' @examples
# varfun.Zaval.2 <- function(vars){
#
#     idC <- vars$Cold$zav.include.strict&(vars$Cold$zav.condition==1)
#     idH <- vars$Heat$zav.include.strict&(vars$Heat$zav.condition==2)
#
#     return(list(Cold = as.numeric(unlist(vars$Cold[idC,1])),
#                 Heat = as.numeric(unlist(vars$Heat[idH,1])),
#                 N    = vars$N))
# }

#' varfun.Knobe.1
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details
#'   \strong{Analysis plan:} Ratings of intentionality in the harm and help conditions will be
#' compared using an independent-samples t-test. This is the focal test for the direct replication.
#' Blame and praise ratings will also be collected but are secondary analyses. All participants with
#' data will be included in analysis.
#'
#' @section Variables:
#'   knob1.3=intentionality (help condition);
#'   knob2.3=intentionality (harm condition);
#'   for both, higher numbers=higher intentionality
#
#' @references Knobe, J. (2003). Intentional action and side effects in ordinary language. Analysis, 63, 190-193.
#'
#' @examples
varfun.Knobe.1 <- function(vars){
    return(list(Help = unlist(vars$Help),
                Harm = unlist(vars$Harm),
                N    = c(length(unlist(vars$Help)), length(unlist(vars$Harm))))
           )
}

#' varfun.Knobe.2
#'
#' @param vars    A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @details
#'   \strong{Analysis plan:} Ratings of intentionality in the harm and help conditions will be
#' compared using an independent-samples t-test. This is the focal test for the direct replication.
#' Blame and praise ratings will also be collected but are secondary analyses. All participants with
#' data will be included in analysis.
#'
#' @section Variables:
#'   knob1.4=intentionality (praise condition);
#'   knob2.4=intentionality (blame condition);
#'   for both, higher numbers=higher intentionality
#
#' @references Knobe, J. (2003). Intentional action and side effects in ordinary language. Analysis, 63, 190-193.
#'
#' @examples
varfun.Knobe.2 <- function(vars){
    return(list(Praise = unlist(vars$Praise),
                Blame  = unlist(vars$Blame),
                N    = c(length(unlist(vars$Praise)), length(unlist(vars$Blame))))
           )
}

#' varfun.Gati.1
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @description \strong{Analysis plan:} We will perform three analyses on the data.
#'
#' For the primary analysis, we will analyze the data through a general linear mixed model with a random effect for the item pair
#' nested within subject, and a fixed factor 'order' representing the order of the pair (prominent first vs. prominent second).
#' Fitting this model will allow evaluation of both effects. If the intercept is significantly greater than 0, this would confirm the finding that at the participant level, if there is an effect for the factor 'order' the pairs where the prominent country appeared second will be rated as more similar than when the prominent country appeared first. We will convert the Beta provided by this intercept term into a Cohen???s d effect size.
#'
#' Second, we will recreate the original analysis used to get a participant-level effect of making similarity judgments where either the more or less prominent country comes first. We will compute an asymmetry score for each subject, calculated as the average similarity for comparisons where the prominent country appears second minus the average for the comparisons where the prominent country appears first. Using a one-sample t-test, we will test this difference score against zero (original d=.48).
#'
#' Third, using a matched-pairs t-test, we will compare the average score for each pair when it was prominent-first compared to prominent-second (original d = 1.31).
#'
#' Because these latter two analyses do not account for the fact that the variance in ratings is
#' crossed between participants and pairs, they will be secondary and only used as a comparison for
#' the original analysis. All participants with data will be included in the analysis.
#'
#' These analyses will be repeated for the differences conditions and reported as a separate study. Because of the random assignment to similarity or difference conditions, each site will have half as much data for its critical test as the other effects. This will likely increase the standard error of its estimates by comparison.
#'
#' @references Tversky, A., & Gati, I. (1978). Studies of similarity. \strong{Cognition and categorization}, 1, 79-98.
#'
#' @examples
varfun.Gati.1 <- function(vars){
#      require(lme4)
#      require(lmerTest)
#      require(reshape2)

  same <- any(grepl("(gati(1|2)(s))+",colnames(vars[[1]])))

  CounterBalanceA <- list(P1st = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22),
                          P2nd = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21))
  CounterBalanceB <- list(P1st = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21),
                          P2nd = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22))
    #
    # CounterBalanceB <- list(P1st = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22),
    #                         P2nd = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21))
    # CounterBalanceA <- list(P1st = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21),
    #                         P2nd = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22))

    dfA     <- vars[[1]]
    dfB     <- vars[[2]]

    dfA$uID <- 1:nrow(dfA)
    dfA$CounterBalance <- 1

    dfB$uID <- 1:nrow(dfB)+nrow(dfA)
    dfB$CounterBalance <- 2

    dfA <- reshape2::melt(dfA,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfA$itemID <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfA$itemID))
    dfA$Condition <- 1
    dfA$Condition[dfA$itemID%in%CounterBalanceA$P2nd] <- 2

    dfB <- reshape2::melt(dfB,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfB$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfB$itemID))
    dfB$Condition <- 1
    dfB$Condition[dfB$itemID%in%CounterBalanceB$P2nd] <- 2

    df <- as.data.frame(rbind(dfA,dfB))

    df$Condition       <- factor(df$Condition,levels=c(1,2),labels=c('Prominent1st','Prominent2nd'))
    if(same){
      df$Condition   <-  relevel(df$Condition,ref = 'Prominent2nd')
    } else {
      df$Condition <-  relevel(df$Condition,ref = 'Prominent1st')
    }
    df$CounterBalance  <- factor(df$CounterBalance,levels=c(1,2),labels=c('CBA','CBB'))

    df <- df[order(df$uID,df$itemID), ]

    #CounterBalance = df$CounterBalance,

    return(list(DV         = df$DV,
                Condition  = df$Condition,
                uID        = df$uID,
                itemID     = df$itemID,
                N          = c(nrow(vars[[1]]),nrow(vars[[2]])))
           )
}

#' varfun.Gati.2
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @description \strong{Analysis plan:} We will perform three analyses on the data.
#'
#' For the primary analysis, we will analyze the data through a general linear mixed model with a random effect for the item pair
#' nested within subject, and a fixed factor 'order' representing the order of the pair (prominent first vs. prominent second).
#' Fitting this model will allow evaluation of both effects. If the intercept is significantly greater than 0, this would confirm the finding that at the participant level, if there is an effect for the factor 'order' the pairs where the prominent country appeared second will be rated as more similar than when the prominent country appeared first. We will convert the Beta provided by this intercept term into a Cohen???s d effect size.
#'
#' Second, we will recreate the original analysis used to get a participant-level effect of making similarity judgments where either the more or less prominent country comes first. We will compute an asymmetry score for each subject, calculated as the average similarity for comparisons where the prominent country appears second minus the average for the comparisons where the prominent country appears first. Using a one-sample t-test, we will test this difference score against zero (original d=.48).
#'
#' Third, using a matched-pairs t-test, we will compare the average score for each pair when it was prominent-first compared to prominent-second (original d = 1.31).
#'
#' Because these latter two analyses do not account for the fact that the variance in ratings is
#' crossed between participants and pairs, they will be secondary and only used as a comparison for
#' the original analysis. All participants with data will be included in the analysis.
#'
#' These analyses will be repeated for the differences conditions and reported as a separate study. Because of the random assignment to similarity or difference conditions, each site will have half as much data for its critical test as the other effects. This will likely increase the standard error of its estimates by comparison.
#'
#' @references Tversky, A., \& Gati, I. (1978). Studies of similarity. \strong{Cognition and categorization}, 1, 79-98.
#'
#' @examples
varfun.Gati.2 <- function(vars){
#    require(dplyr)

  same <- any(grepl("(gati(1|2)(s))+",colnames(vars[[1]])))

    CounterBalanceA <- list(P1st = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22),
                            P2nd = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21))
    CounterBalanceB <- list(P1st = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21),
                            P2nd = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22))

    dfA     <- vars[[1]]
    dfB     <- vars[[2]]

    dfA$uID <- 1:nrow(dfA)
    dfA$CounterBalance <- 1

    dfB$uID <- 1:nrow(dfB)+nrow(dfA)
    dfB$CounterBalance <- 2

    dfA <- reshape2::melt(dfA,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfA$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfA$itemID))
    dfA$Condition <- 1
    dfA$Condition[dfA$itemID%in%CounterBalanceA$P2nd] <- 2

    dfB <- reshape2::melt(dfB,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfB$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfB$itemID))
    dfB$Condition <- 1
    dfB$Condition[dfB$itemID%in%CounterBalanceB$P2nd] <- 2

    df <- as.data.frame(rbind(dfA,dfB))

    df$Condition       <- factor(df$Condition,levels=c(1,2),labels=c('Prominent1st','Prominent2nd'))
    if(same){
      df$Condition   <-  relevel(df$Condition,ref = 'Prominent2nd')
    } else {
      df$Condition <-  relevel(df$Condition,ref = 'Prominent1st')
    }
    df$CounterBalance  <- factor(df$CounterBalance,levels=c(1,2),labels=c('CBA','CBB'))

    #df <- df[order(df$uID,df$itemID), ]

    # Suibject based dataset
    df.subj <- summarize(group_by(df, uID, Condition, CounterBalance),
                         stimDVm = mean(DV,na.rm = TRUE),
                         # study.order = paste0(unique(study.order), collapse = "|"),
                         # Country = paste0(unique(Country), collapse = "|")
                         )

    # df.subj1 <- summarize(group_by(df, uID, Condition, CounterBalance), stimDVsd = sd(DV, na.rm = TRUE))
    # df.subj2 <- summarize(group_by(df, uID, Condition, CounterBalance), Ncases = n())

    df.subj.wide  <- tidyr::spread(df.subj, key = Condition, value = stimDVm)
    # df.subj.wide1 <- tidyr::spread(df.subj1, key = Condition, value = stimDVsd)
    # df.subj.wide2 <- tidyr::spread(df.subj2, key = Condition, value = Ncases)
    #
    # df.subj.wide$Prominent1stSD     <- df.subj.wide1$Prominent1st
    # df.subj.wide$Prominent2ndSD     <- df.subj.wide1$Prominent2nd
    # df.subj.wide$Prominent1stNcases <- df.subj.wide2$Prominent1st
    # df.subj.wide$Prominent2ndNcases <- df.subj.wide2$Prominent2nd
    #
    # df.subj.wide$Asymmetry  = df.subj.wide$Prominent1st-df.subj.wide$Prominent2nd

    if(same){
      Asymmetry <-  df.subj.wide$Prominent2nd-df.subj.wide$Prominent1st
    } else {
      Asymmetry <- df.subj.wide$Prominent1st-df.subj.wide$Prominent2nd
    }


    return(list(Asymmetry  = Asymmetry,
                CompareTo  = 0,
                N          = c(nrow(df.subj.wide),NULL)
                )
           )
}

#' varfun.Gati.3
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @description \strong{Analysis plan:} We will perform three analyses on the data.
#'
#' For the primary analysis, we will analyze the data through a general linear mixed model with a random effect for the item pair
#' nested within subject, and a fixed factor 'order' representing the order of the pair (prominent first vs. prominent second).
#' Fitting this model will allow evaluation of both effects. If the intercept is significantly greater than 0, this would confirm the finding that at the participant level, if there is an effect for the factor 'order' the pairs where the prominent country appeared second will be rated as more similar than when the prominent country appeared first. We will convert the Beta provided by this intercept term into a Cohen???s d effect size.
#'
#' Second, we will recreate the original analysis used to get a participant-level effect of making similarity judgments where either the more or less prominent country comes first. We will compute an asymmetry score for each subject, calculated as the average similarity for comparisons where the prominent country appears second minus the average for the comparisons where the prominent country appears first. Using a one-sample t-test, we will test this difference score against zero (original d=.48).
#'
#' Third, using a matched-pairs t-test, we will compare the average score for each pair when it was prominent-first compared to prominent-second (original d = 1.31).
#'
#' Because these latter two analyses do not account for the fact that the variance in ratings is
#' crossed between participants and pairs, they will be secondary and only used as a comparison for
#' the original analysis. All participants with data will be included in the analysis.
#'
#' These analyses will be repeated for the differences conditions and reported as a separate study. Because of the random assignment to similarity or difference conditions, each site will have half as much data for its critical test as the other effects. This will likely increase the standard error of its estimates by comparison.
#'
#' @references Tversky, A., & Gati, I. (1978). Studies of similarity. \strong{Cognition and categorization}, 1, 79-98.
#'
#' @examples
varfun.Gati.3 <- function(vars){
#    require(dplyr)

  same <- any(grepl("(gati(1|2)(s))+",colnames(vars[[1]])))

  CounterBalanceA <- list(P1st = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22),
                          P2nd = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21))
  CounterBalanceB <- list(P1st = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21),
                          P2nd = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22))

    dfA     <- vars[[1]]
    dfB     <- vars[[2]]

    dfA$uID <- 1:nrow(dfA)
    dfA$CounterBalance <- 1

    dfB$uID <- 1:nrow(dfB)+nrow(dfA)
    dfB$CounterBalance <- 2

    dfA <- reshape2::melt(dfA,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfA$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfA$itemID))
    dfA$Condition <- 1
    dfA$Condition[dfA$itemID%in%CounterBalanceA$P2nd] <- 2

    dfB <- reshape2::melt(dfB,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfB$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfB$itemID))
    dfB$Condition <- 1
    dfB$Condition[dfB$itemID%in%CounterBalanceB$P2nd] <- 2

    df <- as.data.frame(rbind(dfA,dfB))

    df$Condition       <- factor(df$Condition,levels=c(1,2),labels=c('Prominent1st','Prominent2nd'))
    if(same){
      df$Condition   <-  relevel(df$Condition,ref = 'Prominent1st')
    } else {
      df$Condition <-  relevel(df$Condition,ref = 'Prominent2nd')
    }
    df$CounterBalance  <- factor(df$CounterBalance,levels=c(1,2),labels=c('CBA','CBB'))

    df <- df[order(df$uID,df$itemID), ]

    # Item based dataset
    df.stim <- summarize(group_by(df, itemID, Condition), # interaction(Condition, CounterBalance)),
                         stimDV = mean(DV,na.rm = TRUE)
                        #  stimSD = sd(DV, na.rm = TRUE),
                        #  N = n()
                     )

    return(list(DV        = df.stim$stimDV,
                Condition = df.stim$Condition,
                N         = c( sum(df.stim$Condition%in%"Prominent1st"), NULL)
                )
           )
}


#' varfun.Gati.4
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @description \strong{Analysis plan:} We will perform three analyses on the data.
#'
#' For the primary analysis, we will analyze the data through a general linear mixed model with a random effect for the item pair
#' nested within subject, and a fixed factor 'order' representing the order of the pair (prominent first vs. prominent second).
#' Fitting this model will allow evaluation of both effects. If the intercept is significantly greater than 0, this would confirm the finding that at the participant level, if there is an effect for the factor 'order' the pairs where the prominent country appeared second will be rated as more similar than when the prominent country appeared first. We will convert the Beta provided by this intercept term into a Cohen???s d effect size.
#'
#' Second, we will recreate the original analysis used to get a participant-level effect of making similarity judgments where either the more or less prominent country comes first. We will compute an asymmetry score for each subject, calculated as the average similarity for comparisons where the prominent country appears second minus the average for the comparisons where the prominent country appears first. Using a one-sample t-test, we will test this difference score against zero (original d=.48).
#'
#' Third, using a matched-pairs t-test, we will compare the average score for each pair when it was prominent-first compared to prominent-second (original d = 1.31).
#'
#' Because these latter two analyses do not account for the fact that the variance in ratings is
#' crossed between participants and pairs, they will be secondary and only used as a comparison for
#' the original analysis. All participants with data will be included in the analysis.
#'
#' These analyses will be repeated for the differences conditions and reported as a separate study. Because of the random assignment to similarity or difference conditions, each site will have half as much data for its critical test as the other effects. This will likely increase the standard error of its estimates by comparison.
#'
#' @note This analysis tests moderating effect of presenting Norenzayan first or after.
#'
#' @references Tversky, A., & Gati, I. (1978). Studies of similarity. \strong{Cognition and categorization}, 1, 79-98.
#'
#' @examples
varfun.Gati.4 <- function(vars){

  same <- any(grepl("(gati(1|2)(s))+",colnames(vars[[1]])))

  CounterBalanceA <- list(P1st = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22),
                          P2nd = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21))
  CounterBalanceB <- list(P1st = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21),
                          P2nd = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22))

    dfA     <- vars[[1]]
    dfB     <- vars[[2]]

    dfA$uID <- 1:nrow(dfA)
    dfA$CounterBalance <- 1

    dfB$uID <- 1:nrow(dfB)+nrow(dfA)
    dfB$CounterBalance <- 2

    dfA <- reshape2::melt(dfA,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfA$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfA$itemID))
    dfA$Condition <- 1
    dfA$Condition[dfA$itemID%in%CounterBalanceA$P2nd] <- 2

    dfB <- reshape2::melt(dfB,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

    dfB$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfB$itemID))
    dfB$Condition <- 1
    dfB$Condition[dfB$itemID%in%CounterBalanceB$P2nd] <- 2

    df <- as.data.frame(rbind(dfA,dfB))

    df$Condition       <- factor(df$Condition,levels=c(1,2),labels=c('Prominent1st','Prominent2nd'))
    if(same){
      df$Condition   <-  relevel(df$Condition,ref = 'Prominent1st')
    } else {
      df$Condition <-  relevel(df$Condition,ref = 'Prominent2nd')
    }
    df$CounterBalance  <- factor(df$CounterBalance,levels=c(1,2),labels=c('CBA','CBB'))

    df <- df[order(df$uID,df$itemID), ]

    # Suibject based dataset
    df.subj <- summarize(group_by(df, uID, Condition),
                         stimDV = mean(DV,na.rm = TRUE)
    )

    df.subj.wide <- tidyr::spread(df.subj, key = Condition, value = stimDV)


TGafterN.cbA <- sapply(which((vars$RawDataFilter[[1]]$Included)), function(i) which(unlist(strsplit(x = vars$RawDataFilter[[1]]$StudyOrderN[i], split = "[|]")) == "Tversky.Gati") > which(unlist(strsplit(x = vars$RawDataFilter[[1]]$StudyOrderN[i], split = "[|]")) == "Norenzayan"))
TGafterN.cbB <- sapply(which((vars$RawDataFilter[[2]]$Included)), function(i) which(unlist(strsplit(x = vars$RawDataFilter[[2]]$StudyOrderN[i], split = "[|]")) == "Tversky.Gati") > which(unlist(strsplit(x = vars$RawDataFilter[[2]]$StudyOrderN[i], split = "[|]")) == "Norenzayan"))

TGafterN.cbA <- unlist(TGafterN.cbA)
TGafterN.cbB <- unlist(TGafterN.cbB)

Order.n <- c(as.numeric(TGafterN.cbA), as.numeric(TGafterN.cbB))

if(same){
  Asymmetry <-  df.subj.wide$Prominent2nd-df.subj.wide$Prominent1st
  } else {
    Asymmetry <- df.subj.wide$Prominent1st-df.subj.wide$Prominent2nd
    }

return(list(Asymmetry  = Asymmetry,
            Order      = factor(Order.n, levels=c(0,1), labels = vars$labels$Order),
            N          = c(sum(Order.n==0,na.rm = TRUE),sum(Order.n==1,na.rm = TRUE))
)
)


# dfA$asym <- rowMeans(dplyr::select(dfA,which(as.numeric(gsub("(gati(1|2)(s|d)[.])","",colnames(dfA)))%in%CounterBalanceA$P2nd)),na.rm=TRUE)-rowMeans(select(dfA,which(as.numeric(gsub("(gati(1|2)(s|d)[.])","",colnames(dfA)))%in%CounterBalanceA$P1st)),na.rm=TRUE)
#
# dfB$asym <- rowMeans(dplyr::select(dfB,which(as.numeric(gsub("(gati(1|2)(s|d)[.])","",colnames(dfB)))%in%CounterBalanceB$P2nd)),na.rm=TRUE)-rowMeans(select(dfB,which(as.numeric(gsub("(gati(1|2)(s|d)[.])","",colnames(dfB)))%in%CounterBalanceB$P1st)),na.rm=TRUE)

return(list(Asymmetry  = c(dfA$asym,dfB$asym),
            Order      = factor(c(as.numeric(TGafterN.cbA), as.numeric(TGafterN.cbB)), levels=c(0,1), labels = vars$labels$Order),
            N          = c(length(dfA$asym),length(dfB$asym)))
       )
}


#' varfun.Gati.5
#'
#' @param vars     A list object generated by \code{\link{get.sourceData}} containing cleaned data and variable labels.
#'
#' @return
#' @export
#'
#' @description \strong{Analysis plan:} We will perform three analyses on the data.
#'
#'
#' @references Tversky, A., & Gati, I. (1978). Studies of similarity. \strong{Cognition and categorization}, 1, 79-98.
#'
#' @examples
varfun.Gati.5 <- function(vars){
  #    require(dplyr)

  same <- any(grepl("(gati(1|2)(s))+",colnames(vars[[1]])))

  CounterBalanceA <- list(P1st = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22),
                          P2nd = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21))
  CounterBalanceB <- list(P1st = c(4, 6, 7, 8, 9, 10, 13, 15, 20, 21),
                          P2nd = c(2, 3, 5, 11, 12, 14, 16, 17, 18, 19, 22))

  dfA     <- vars[[1]]
  dfB     <- vars[[2]]

  dfA$uID <- 1:nrow(dfA)
  dfA$CounterBalance <- 1

  dfB$uID <- 1:nrow(dfB)+nrow(dfA)
  dfB$CounterBalance <- 2

  dfA <- reshape2::melt(dfA,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

  dfA$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfA$itemID))
  dfA$Condition <- 1
  dfA$Condition[dfA$itemID%in%CounterBalanceA$P2nd] <- 2

  dfB <- reshape2::melt(dfB,id=c('uID','CounterBalance'),variable.name='itemID',value.name='DV',factorsAsStrings = FALSE)

  dfB$itemID    <- as.numeric(gsub("(gati(1|2)(s|d)[.])","",dfB$itemID))
  dfB$Condition <- 1
  dfB$Condition[dfB$itemID%in%CounterBalanceB$P2nd] <- 2

  df <- as.data.frame(rbind(dfA,dfB))

  df$Condition       <- factor(df$Condition,levels=c(1,2),labels=c('Prominent1st','Prominent2nd'))
  if(same){
    df$Condition   <-  relevel(df$Condition,ref = 'Prominent1st')
  } else {
    df$Condition <-  relevel(df$Condition,ref = 'Prominent2nd')
  }
  df$CounterBalance  <- factor(df$CounterBalance,levels=c(1,2),labels=c('CBA','CBB'))

  df <- df[order(df$uID,df$itemID), ]

  # Item based dataset
  df.stim <- summarize(group_by(df, itemID, Condition),
                       stimDV = mean(DV,na.rm = TRUE),
                       stimSD = sd(DV, na.rm = TRUE),
                       N = n()
  )

  return(list(DV        = df.stim$stimDV,
              Condition = df.stim$Condition,
              N         = c( sum(df.stim$Condition%in%"Prominent1st"), NULL))
         )
}



